{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4304c100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Hp/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FAISS, BM25, metadata, and models...\n",
      "\n",
      "Query: What is the Balance as at March 31, 2024 for accumulated deficit?\n",
      "\n",
      "Final Answer:\n",
      "  Based on the information provided in the context, the accumulated deficit value as at March 31, 2024 is \"(1020518)\". This value is included in the \"accumulated deficit values\" key under the years 2024 in the context.\n",
      "\n",
      "Top supporting docs:\n",
      "[10] (chunk=100, score=-3.544) -> Total current assets values: {\"2024\": \"857278\", \"2025\": \"1065268\"} Total assets values: {\"2024\": \"1660077\", \"2025\": \"182...\n",
      "[1] (chunk=100, score=-5.060) -> Current tax assets values: {\"2024\": \"4947\"} Trade and other receivables values: {\"2023\": \"68847\", \"2024\": \"91950\"} Term ...\n",
      "[7] (chunk=100, score=-7.756) -> Diluted values: {\"2022\": \"(0.42)\", \"2023\": \"(0.10)\", \"2024\": \"1.74\"} Profit (loss) for the year values: {\"2022\": \"(45567...\n",
      "[23] (chunk=400, score=-7.808) -> Personnel expenses values: {\"2022\": \"116924\", \"2023\": \"131968\", \"2024\": \"147587\"} Marketing and sales promotion expenses...\n",
      "[27] (chunk=400, score=-7.813) -> Proceeds from bank loans (refer note 28) values: {\"2023\": \"2168\", \"2024\": \"2114\"} Repayment of bank loans (refer note 28...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import faiss\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
    "from rank_bm25 import BM25Okapi\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import requests\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "\n",
    "# ---------------- Paths & Models ----------------\n",
    "EMBED_MODEL   = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "CROSS_ENCODER = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "OUT_DIR       = \"data/index_merged\"\n",
    "\n",
    "FAISS_PATH = os.path.join(OUT_DIR, \"faiss_merged.index\")\n",
    "BM25_PATH  = os.path.join(OUT_DIR, \"bm25_merged.pkl\")\n",
    "META_PATH  = os.path.join(OUT_DIR, \"meta_merged.pkl\")\n",
    "\n",
    "BLOCKED_TERMS = [\"weather\",\"cricket\",\"movie\",\"song\",\"football\",\"holiday\",\n",
    "                 \"travel\",\"recipe\",\"music\",\"game\",\"sports\",\"politics\",\"election\"]\n",
    "\n",
    "FINANCE_DOMAINS = [\n",
    "    \"financial reporting\",\"balance sheet\",\"income statement\",\"assets and liabilities\",\n",
    "    \"equity\",\"revenue\",\"profit and loss\",\"goodwill impairment\",\"cash flow\",\"dividends\",\n",
    "    \"taxation\",\"investment\",\"valuation\",\"capital structure\",\"ownership interests\",\n",
    "    \"subsidiaries\",\"shareholders equity\",\"expenses\",\"earnings\",\"debt\",\"amortization\",\"depreciation\"\n",
    "]\n",
    "\n",
    "# ---------------- Load Indexes ----------------\n",
    "print(\"Loading FAISS, BM25, metadata, and models...\")\n",
    "faiss_index = faiss.read_index(FAISS_PATH)\n",
    "\n",
    "with open(BM25_PATH, \"rb\") as f:\n",
    "    bm25_obj = pickle.load(f)\n",
    "bm25 = bm25_obj[\"bm25\"]\n",
    "\n",
    "with open(META_PATH, \"rb\") as f:\n",
    "    meta: List[Dict] = pickle.load(f)\n",
    "\n",
    "embed_model = SentenceTransformer(EMBED_MODEL)\n",
    "reranker = CrossEncoder(CROSS_ENCODER)\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://router.huggingface.co/v1\",\n",
    "    api_key=\"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\"\n",
    ")\n",
    "\n",
    "# ---------------- Hugging Face Mistral API ----------------\n",
    "#HF_TOKEN = \"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\"\n",
    "#HF_MODEL = \"mistralai/Mistral-7B-Instruct-v0.2:featherless-ai\"\n",
    "\n",
    "def get_mistral_answer(query: str, context: str) -> str:\n",
    "    \"\"\"\n",
    "    Calls Mistral 7B Instruct API via Hugging Face Inference API.\n",
    "    \"\"\"\n",
    "    prompt = f\"Context:\\n{context}\\n\\nQuestion: {query}\\nAnswer in full sentences using context.\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"mistralai/Mistral-7B-Instruct-v0.2:featherless-ai\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return str(completion.choices[0].message.content)\n",
    "\n",
    "# ---------------- Guardrails ----------------\n",
    "finance_embeds = embed_model.encode(FINANCE_DOMAINS, convert_to_tensor=True)\n",
    "\n",
    "def validate_query(query: str, threshold: float = 0.5) -> bool:\n",
    "    q_lower = query.lower()\n",
    "    if any(bad in q_lower for bad in BLOCKED_TERMS):\n",
    "        return False\n",
    "    q_emb = embed_model.encode(query, convert_to_tensor=True)\n",
    "    sim_scores = util.cos_sim(q_emb, finance_embeds)\n",
    "    return float(sim_scores.max()) > threshold\n",
    "\n",
    "# ---------------- Preprocess ----------------\n",
    "def preprocess_query(query: str, remove_stopwords: bool = True) -> str:\n",
    "    query = query.lower()\n",
    "    query = re.sub(r\"[^a-z0-9\\s]\", \" \", query)\n",
    "    tokens = query.split()\n",
    "    if remove_stopwords:\n",
    "        tokens = [t for t in tokens if t not in STOPWORDS]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# ---------------- Hybrid Retrieval ----------------\n",
    "def hybrid_candidates(query: str, candidate_k: int = 50, alpha: float = 0.5) -> List[int]:\n",
    "    q_emb = embed_model.encode([preprocess_query(query, remove_stopwords=False)], convert_to_numpy=True, normalize_embeddings=True)\n",
    "    faiss_scores, faiss_ids = faiss_index.search(q_emb, max(candidate_k, 50))\n",
    "    faiss_ids = faiss_ids[0]\n",
    "    faiss_scores = faiss_scores[0]\n",
    "\n",
    "    tokenized_query = preprocess_query(query).split()\n",
    "    bm25_scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "    topN = max(candidate_k, 50)\n",
    "    bm25_top = np.argsort(bm25_scores)[::-1][:topN]\n",
    "    faiss_top = faiss_ids[:topN]\n",
    "    union_ids = np.unique(np.concatenate([bm25_top, faiss_top]))\n",
    "\n",
    "    faiss_score_map = {int(i): float(s) for i, s in zip(faiss_ids, faiss_scores)}\n",
    "    f_arr = np.array([faiss_score_map.get(int(i), -1.0) for i in union_ids], dtype=float)\n",
    "    f_min = np.min(f_arr)\n",
    "    if np.any(f_arr < 0):\n",
    "        f_arr = np.where(f_arr < 0, f_min, f_arr)\n",
    "    b_arr = np.array([bm25_scores[int(i)] for i in union_ids], dtype=float)\n",
    "\n",
    "    def _norm(x): return (x - np.min(x)) / (np.ptp(x) + 1e-9)\n",
    "    combined = alpha * _norm(f_arr) + (1 - alpha) * _norm(b_arr)\n",
    "    order = np.argsort(combined)[::-1]\n",
    "    return union_ids[order][:candidate_k].tolist()\n",
    "\n",
    "# ---------------- Cross-Encoder Rerank ----------------\n",
    "def rerank_cross_encoder(query: str, cand_ids: List[int], top_k: int = 10) -> List[Dict]:\n",
    "    pairs = [(query, meta[i][\"content\"]) for i in cand_ids]\n",
    "    scores = reranker.predict(pairs)\n",
    "    order = np.argsort(scores)[::-1][:top_k]\n",
    "    return [{\"id\": cand_ids[i], \"chunk_size\": meta[cand_ids[i]][\"chunk_size\"], \"content\": meta[cand_ids[i]][\"content\"], \"rerank_score\": float(scores[i])} for i in order]\n",
    "\n",
    "# ---------------- Extract Numeric ----------------\n",
    "def extract_value_for_year_and_concept(year: str, concept: str, context_docs: List[Dict]) -> str:\n",
    "    target_year = str(year)\n",
    "    concept_lower = concept.lower()\n",
    "    for doc in context_docs:\n",
    "        text = doc.get(\"content\", \"\")\n",
    "        lines = [line for line in text.split(\"\\n\") if line.strip() and any(c.isdigit() for c in line)]\n",
    "        header_idx = None\n",
    "        year_to_col = {}\n",
    "        for idx, line in enumerate(lines):\n",
    "            years_in_line = re.findall(r\"20\\d{2}\", line)\n",
    "            if years_in_line:\n",
    "                for col_idx, y in enumerate(years_in_line):\n",
    "                    year_to_col[y] = col_idx\n",
    "                header_idx = idx\n",
    "                break\n",
    "        if target_year not in year_to_col or header_idx is None:\n",
    "            continue\n",
    "        for line in lines[header_idx+1:]:\n",
    "            if concept_lower in line.lower():\n",
    "                cols = re.split(r\"\\s{2,}|\\t\", line)\n",
    "                col_idx = year_to_col[target_year]\n",
    "                if col_idx < len(cols):\n",
    "                    return cols[col_idx].replace(\",\", \"\")\n",
    "    return None\n",
    "\n",
    "# ---------------- RAG Pipeline ----------------\n",
    "def rag_pipeline(query: str, top_k: int = 5, candidate_k: int = 50, alpha: float = 0.6):\n",
    "    if not validate_query(query):\n",
    "        return \"Query rejected: Please ask finance-related questions.\", []\n",
    "\n",
    "    cand_ids = hybrid_candidates(query, candidate_k=candidate_k, alpha=alpha)\n",
    "    reranked = rerank_cross_encoder(query, cand_ids, top_k=top_k)\n",
    "\n",
    "    year_match = re.search(r\"(20\\d{2})\", query)\n",
    "    year = year_match.group(0) if year_match else None\n",
    "    concept = re.sub(r\"for the year 20\\d{2}\", \"\", query, flags=re.IGNORECASE).strip()\n",
    "\n",
    "    year_specific_answer = None\n",
    "    if year and concept:\n",
    "        year_specific_answer = extract_value_for_year_and_concept(year, concept, reranked)\n",
    "\n",
    "    if year_specific_answer:\n",
    "        answer = year_specific_answer\n",
    "    else:\n",
    "        # Pass top 5 chunks as context\n",
    "        context_text = \"\\n\".join([d[\"content\"] for d in reranked])\n",
    "        answer = get_mistral_answer(query, context_text)\n",
    "\n",
    "    return answer, reranked\n",
    "\n",
    "# ---------------- Example ----------------\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"What is the Balance as at March 31, 2024 for accumulated deficit?\"\n",
    "    answer, top_docs = rag_pipeline(query)\n",
    "\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(\"\\nFinal Answer:\\n\", answer)\n",
    "    print(\"\\nTop supporting docs:\")\n",
    "    for doc in top_docs:\n",
    "        print(f\"[{doc['id']}] (chunk={doc['chunk_size']}, score={doc['rerank_score']:.3f}) -> {doc['content'][:120]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60df5cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
